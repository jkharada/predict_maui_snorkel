{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64faca63-b228-4ef7-99b8-43468ec4d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from pytesseract import pytesseract\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from ediblepickle import checkpoint\n",
    "#from string import Template\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3726b95e-4e1c-4c65-9b10-9b6e4a1bb5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bw(image):\n",
    "    \"\"\"\n",
    "    Converts images to black and white instead of colored, which helps\n",
    "    tesseract read them\n",
    "    \"\"\"\n",
    "    monocolor = image.convert('L')\n",
    "    return monocolor.point(lambda x: 0 if x < 240 else 255, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56293db2-8bea-4144-a3c9-9cd506da7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snorkel_text(image_path):\n",
    "    \"\"\"\n",
    "    Gets text (specifically, date, decription, and numbers) from snorkel reports\n",
    "    and returns them as a list of text lines. There are two formats (.jpg/jpeg and .png), which have\n",
    "    slightly different placements data placements. \n",
    "    \n",
    "    Input: image file\n",
    "    Returns: Raw text output from tesseract in the form:\n",
    "            (date, description, [number 1, number 2, number 3])\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    height, width = img.size\n",
    "#    print(image_path)\n",
    "    \n",
    "    # Tesseract doesn't read columns of numbers well, so numbers are cropped into seperate boxes.\n",
    "    \n",
    "    if '.png' in image_path:\n",
    "        num_left = width * 75 / 100\n",
    "        num_right = width * 98 / 100\n",
    "\n",
    "        num1_top = width * 25 / 100\n",
    "        num1_bottom = width * 42 / 100\n",
    "\n",
    "        num2_top = width * 45 / 100\n",
    "        num2_bottom = width * 62 / 100\n",
    "\n",
    "        num3_top = width * 66 / 100\n",
    "        num3_bottom = width * 83 / 100\n",
    "\n",
    "        text_left = 0\n",
    "        text_right = width * 74.5 / 100\n",
    "        text_top = width * 21 / 100\n",
    "        text_bottom = width * 84 / 100\n",
    "\n",
    "        date_left = width * 52 /100\n",
    "        date_right = width * 99 / 100\n",
    "        date_top = height * 5 / 100\n",
    "        date_bottom = height * 12 / 100\n",
    "        \n",
    "    else:\n",
    "        num_left = width * 74.5 / 100\n",
    "        num_right = width * 88 / 100\n",
    "\n",
    "        num1_top = width * 18 / 100\n",
    "        num1_bottom = width * 35 / 100\n",
    "\n",
    "        num2_top = width * 38 / 100\n",
    "        num2_bottom = width * 55 / 100\n",
    "\n",
    "        num3_top = width * 58 / 100\n",
    "        num3_bottom = width * 75 / 100\n",
    "\n",
    "        text_left = 0\n",
    "        text_right = num_left\n",
    "        text_top = width * 18 / 100\n",
    "        text_bottom = width * 80 / 100\n",
    "\n",
    "        date_left = width * 11.5 /100\n",
    "        date_right = width * 50 / 100\n",
    "        date_top = height * 12 / 100\n",
    "        date_bottom = text_top\n",
    "    \n",
    "    im_description = img.crop((text_left, text_top, text_right, text_bottom))\n",
    "    im_1_number = img.crop((num_left, num1_top, num_right, num1_bottom))\n",
    "    im_2_number = img.crop((num_left, num2_top, num_right, num2_bottom))\n",
    "    im_3_number = img.crop((num_left, num3_top, num_right, num3_bottom))\n",
    "    im_date = img.crop((date_left, date_top, date_right, date_bottom))\n",
    "    \n",
    " \n",
    "    im_text_description = pytesseract.image_to_string(im_description).strip()\n",
    "    im_text_date = pytesseract.image_to_string(im_date, config='--psm 7').strip()\n",
    "    \n",
    "    # Limit tesseract readings to numbers and period and only reads one line (or char?) of text\n",
    "    # Results in a more accurate text conversion\n",
    "    num_config = \"--psm 10 -c tessedit_char_whitelist=0123456789.\"\n",
    "    im_text_1number = pytesseract.image_to_string(convert_to_bw(im_1_number), config=num_config).strip()\n",
    "    im_text_2number = pytesseract.image_to_string(convert_to_bw(im_2_number), config=num_config).strip()\n",
    "    im_text_3number = pytesseract.image_to_string(convert_to_bw(im_3_number), config=num_config).strip()\n",
    "    \n",
    "    return im_text_date, im_text_description, [im_text_1number, im_text_2number, im_text_3number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2fad7b-2eb5-48ed-a01e-56d8ab06e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snorkel_text_new_format(image_path):\n",
    "    \"\"\"\n",
    "    Gets text (specifically, date, decription, and numbers) from the new format snorkel reports\n",
    "    and returns them as a list of text lines. \n",
    "    \n",
    "    Input: image file\n",
    "    Returns: Raw text output from tesseract in the form:\n",
    "            (date, description, [number 1, number 2, number 3])\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    height, width = img.size\n",
    "    \n",
    "    # Tesseract doesn't read columns of numbers well, so numbers are cropped into seperate boxes.\n",
    "#     num_left = width * 78 / 100\n",
    "#     num_right = width * 94 / 100\n",
    "\n",
    "#     num1_top = width * 27 / 100\n",
    "#     num1_bottom = width * 40 / 100\n",
    "\n",
    "#     num2_top = width * 47 / 100\n",
    "#     num2_bottom = width * 60 / 100\n",
    "\n",
    "#     num3_top = width * 68 / 100\n",
    "#     num3_bottom = width * 81 / 100\n",
    "\n",
    "    num_left = width * 75 / 100\n",
    "    num_right = width * 98 / 100\n",
    "\n",
    "    num1_top = width * 25 / 100\n",
    "    num1_bottom = width * 42 / 100\n",
    "\n",
    "    num2_top = width * 45 / 100\n",
    "    num2_bottom = width * 62 / 100\n",
    "\n",
    "    num3_top = width * 66 / 100\n",
    "    num3_bottom = width * 83 / 100\n",
    "\n",
    "    text_left = 0\n",
    "    text_right = width * 74.5 / 100\n",
    "    text_top = width * 21 / 100\n",
    "    text_bottom = width * 84 / 100\n",
    "\n",
    "    date_left = width * 56 /100\n",
    "    date_right = width * 98 / 100\n",
    "    date_top = height * 5 / 100\n",
    "    date_bottom = height * 12 / 100\n",
    "\n",
    "    im_description = img.crop((text_left, text_top, text_right, text_bottom))\n",
    "    im_1_number = img.crop((num_left, num1_top, num_right, num1_bottom))\n",
    "    im_2_number = img.crop((num_left, num2_top, num_right, num2_bottom))\n",
    "    im_3_number = img.crop((num_left, num3_top, num_right, num3_bottom))\n",
    "    im_date = img.crop((date_left, date_top, date_right, date_bottom))\n",
    "    \n",
    "    im_text_description = pytesseract.image_to_string(im_description).strip()\n",
    "    im_text_date = pytesseract.image_to_string(im_date, config='--psm 7').strip()\n",
    "    \n",
    "    # Limit tesseract readings to numbers and period and only reads one line (or char?) of text\n",
    "    # Results in a more accurate text conversion\n",
    "    num_config = \"--psm 10 -c tessedit_char_whitelist=0123456789.\"\n",
    "    im_text_1number = pytesseract.image_to_string(convert_to_bw(im_1_number), config=num_config).strip()\n",
    "    im_text_2number = pytesseract.image_to_string(convert_to_bw(im_2_number), config=num_config).strip()\n",
    "    im_text_3number = pytesseract.image_to_string(convert_to_bw(im_3_number), config=num_config).strip()\n",
    "    \n",
    "    return im_text_date, im_text_description, [im_text_1number, im_text_2number, im_text_3number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c163d75-6f12-4a72-803f-80456489562e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Saturday, March 11 2023',\n",
       " \"Northwest (Napili, Kapalua, Honolua)\\ne Smallest waves inside Kapalua Bay\\n\\ne Powerful waves & currents today\\n\\ne Mostly sunny with light winds\\n\\nKa'anapali (Black Rock, Kahekili-Airport Beach)\\ne Kahekili & Black Rock both fantastic!\\n\\ne Still some surf along the shoreline\\n\\ne Sunny skies & calm winds likely\\n\\nSouth Shore (Olowalu, Kihei, Makena Landing)\\ne Mile Marker 14 is the most calm\\n\\ne Biggest waves in Makena & Wailea\\n\\ne Sunshine & fairly calm winds expected\",\n",
       " ['2.0', '7.5', '4.0'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_snorkel_text_new_format(cmd_path + 'new_format.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a187f8-231a-4eea-9e1a-81cfa0b39626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_output_to_list(image_to_text):\n",
    "    \"\"\"\n",
    "    inputs description text into a formatted list of lists. Inner list has the format\n",
    "    columns = ['date', south_description', 'south_rating', 'kaanapali_description', 'kaanapali_rating',\n",
    "                'northwest_description', 'northwest_rating']\n",
    "    \n",
    "    \"\"\"\n",
    "    im_text_date, im_text_description, im_numbers = image_to_text\n",
    "    # split_descripts = im_text_description.split('\\n\\n')\n",
    "    \n",
    "    # Assigns numbers and descriptions to each region according to their index within the image description\n",
    "    # Find kaanapali via 'anapa' due to spelling error in images\n",
    "    region_list = [(im_text_description.find('South'), 'south'), (im_text_description.find('anapa'), 'kaanapali'), \\\n",
    "                   (im_text_description.find('West' or 'North'), 'northwest') ]\n",
    "    \n",
    "    region_score = {}\n",
    "    for i, region in enumerate(sorted(region_list, key=lambda x: x[0])):\n",
    "        region_score[region[1]] = im_numbers[i]\n",
    "    \n",
    "    # Remove misc characters from date\n",
    "    #print(im_text_date)\n",
    "#    date = re.findall(r\"([MTWFS]\\S+day, [JFMASOND]\\S+ \\d\\d? 20\\d\\d)\", im_text_date)[0]\n",
    "#    date = re.findall(r\"([JFMASOND]\\S+ \\d\\d? 20\\d\\d)\", im_text_date)[0]\n",
    "    \n",
    "    return im_text_date, im_text_description, region_score['south'], region_score['kaanapali'], region_score['northwest']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06a63e4-ff21-40ac-9ba7-4c069e3cfd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_months_data(cmd_path, month, year):\n",
    "    if os.path.isfile(cmd_path + 'cache/' + str(year) + '_' + month + '.p'):\n",
    "        with open(cmd_path + 'cache/' + str(year) + '_' + month + '.p', 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    data = []\n",
    "    path = cmd_path + \"Maui_Snorkel_Report_\" + str(year) + '/' + month + '/'\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    for file in files:\n",
    "        if not file.startswith('.'):\n",
    "            data.append(img_output_to_list(get_snorkel_text(path + file)))\n",
    "        \n",
    "    with open(cmd_path + 'cache/' + str(year) + '_' + month + '.p', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "              \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17b0506a-2f36-4446-b41c-d833954ad4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_months_data_new_format(cmd_path, month, year):\n",
    "    if os.path.isfile(cmd_path + 'cache/' + str(year) + '_' + month + '.p'):\n",
    "        with open(cmd_path + 'cache/' + str(year) + '_' + month + '.p', 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    data = []\n",
    "    path = cmd_path + \"Maui_Snorkel_Report_\" + str(year) + '/' + month + '/'\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    for file in files:\n",
    "        if not file.startswith('.'):\n",
    "            data.append(img_output_to_list(get_snorkel_text_new_format(path + file)))\n",
    "        \n",
    "    with open(cmd_path + 'cache/' + str(year) + '_' + month + '.p', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "              \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7946da1-8d03-4a65-ad75-3ca8d53de956",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_path = r\"/Users/jkharada/Documents/Data_incubator/Capstone_project/snorkel_reports/\"\n",
    "old_years = [2017, 2018, 2019, 2020, 2021, 2022]\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "new_years = [2022, 2023]\n",
    "\n",
    "data = []\n",
    "# Get data in the old format\n",
    "for yr in old_years:\n",
    "    for mo in months:\n",
    "        data += (get_months_data_old_format(cmd_path, mo, yr))\n",
    "        \n",
    "# Get data in new format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a7099e-ca7d-4467-b8cc-ca948cb21dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/1wkn526x7pzdr03mqh7m7vnm0000gn/T/ipykernel_32443/2541706785.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced.drop(list(range(2032, 2095)), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['date', 'description', 'south_rating', 'kaanapali_rating', 'northwest_rating'])\n",
    "df_reduced = df[['date','south_rating','kaanapali_rating','northwest_rating']]\n",
    "df_reduced.drop(list(range(2032, 2095)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d242fbd-afe9-4d76-9516-77a463509ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.drop([2012, 2013, 2014,2015, 2018, 2021, 2024, 2027, 2028], inplace = True)\n",
    "df_reduced[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "309face0-bf69-44ba-9030-dddf2718c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "for yr in new_years:\n",
    "    for mo in months:\n",
    "        new_data += (get_months_data_new_format(cmd_path, mo, yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab789ba9-3e9e-4d58-a182-2f8102448466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new_data = pd.DataFrame(new_data, columns=['date', 'description', 'south_rating', 'kaanapali_rating', 'northwest_rating'])\n",
    "df_new_reduced = df_new_full[['date','south_rating','kaanapali_rating','northwest_rating']]\n",
    "df_new_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b74f28-9aab-44cc-a200-e03ec8dac383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_data.drop(list(range(278,365)), inplace=True)\n",
    "df_new_full = pd.concat([df_new_data, df_oct_2022, df_nov_2022, df_dec_2022])\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(df_new_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c702dd91-d8c4-4ef5-a8c7-7ccc26660cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_full.to_csv(cmd_path + 'new_format_data_Jan2022_current.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd85fed-2383-482c-a9e6-e68cd859591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2016 = []\n",
    "months = ['June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "#path = cmd_path + \"Maui_Snorkel_Report_2016/\" + month + '/'\n",
    "#files = os.listdir(path)\n",
    "\n",
    "for mo in months:\n",
    "    data_2016 += (get_months_data(cmd_path, mo, 2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bd83faa-3ecf-4324-bfde-3eb50335a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_2022_data = get_months_data_new_format(cmd_path, 'December', 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "151446cf-4790-4e59-88f0-ce93b5290d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dec_2022 = pd.DataFrame(dec_2022_data, columns=['date', 'description', 'south_rating', 'kaanapali_rating', 'northwest_rating'])\n",
    "#df_oct_2022 = df_oct_2022[['date', 'south_rating', 'kaanapali_rating', 'northwest_rating']]\n",
    "#df_oct_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5f02c19-dcb7-4620-a207-0445bf55912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = pd.DataFrame(data_2016, columns=['date', 'description', 'south_rating', 'kaanapali_rating', 'northwest_rating'])\n",
    "df_2016.to_csv(cmd_path+'data_2016.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d33b9770-9036-4ce5-9d44-30e79e534420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'.png' in '/Users/jkharada/Documents/Data_incubator/Capstone_project/snorkel_reports/Maui_Snorkel_Report_2022/October/OCTOBER-17-2022.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b858b191-37ec-4015-be5f-6a5ae9055f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_path = r\"/Users/jkharada/Documents/Data_incubator/Capstone_project/snorkel_reports/\"\n",
    "\n",
    "old_format_full = pd.read_csv('/Users/jkharada/Documents/Data_incubator/Capstone_project/old_format_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78263bf-9641-44c4-90bd-ef6ccdec3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(df_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c0b175e-d131-443c-a6dc-8043329dd534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hand edited dataset (edited to fix dates, some missing values)\n",
    "\n",
    "full_dataset = pd.read_csv(cmd_path + 'full_dataset_hand_edited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9e815a30-c8f0-4e7c-844c-f8cead096b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get uniformly formatted dates (those in datasets have misc periods and extra values, mispellings, missing spaces, etc)\n",
    "full_dataset['parsed_date'] = full_dataset['date'].apply(lambda x: ' '.join(list(re.findall(r\"([JFMASOND][a-z]+),? ?(\\d\\d?).?,? ?(20\\d\\d)\", x)[0]))\n",
    "                                if re.search(r\"([JFMASOND][a-z]+),? ?(\\d\\d?).?,? ?(20\\d\\d)\", x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ca9b04b2-80f6-4476-88ce-e6ba32b5d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset['cleaned_south_rating'] = full_dataset['south_rating'].apply(lambda x: x/10 if x > 10 else x)\n",
    "full_dataset['cleaned_kaanapali_rating'] = full_dataset['kaanapali_rating'].apply(lambda x: x/10 if x > 10 else x)\n",
    "full_dataset['cleaned_northwest_rating'] = full_dataset['northwest_rating'].apply(lambda x: x/10 if x > 10 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "df934f06-b151-46ca-9001-8fb564239ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns and standardize data\n",
    "cleaned_usable_dataset = full_dataset[['parsed_date', 'cleaned_south_rating', 'cleaned_kaanapali_rating', 'cleaned_northwest_rating']].dropna()\n",
    "cleaned_usable_dataset.rename(columns= {'parsed_date':'date', 'cleaned_south_rating':'south_rating', \n",
    "                                        'cleaned_kaanapali_rating':'kaanapali_rating', 'cleaned_northwest_rating':'northwest_rating'},\n",
    "                             inplace=True)\n",
    "cleaned_usable_dataset['date'] = pd.to_datetime(cleaned_usable_dataset['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6aa59a61-3db2-4d3d-9222-34b6b02363cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output cleaned data to csv\n",
    "cleaned_usable_dataset.to_csv(cmd_path+'cleaned_usable_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0884a9-659b-47dd-a59f-adc954d67d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(cleaned_usable_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
